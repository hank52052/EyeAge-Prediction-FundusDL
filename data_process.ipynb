{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8b9c0-5f0e-4b08-aa3b-ac28ee5c4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def load_images_and_labels(csv_path):\n",
    "    df = pd.read_csv(csv_path, index_col=0)\n",
    "    def load_and_resize(i):\n",
    "        img_path = df.loc[i, \"IMAGE_FILENAME\"]\n",
    "        age = df.loc[i, \"AGE\"]\n",
    "        path = \"/work1043/yuhung0716/blur_images_result/Original_images_cropped/crop_images/\" + img_path + \".jpg\"\n",
    "        try:\n",
    "            img = cv2.imread(path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (299, 299))\n",
    "                return img, age\n",
    "        except:\n",
    "            pass\n",
    "        return None, None\n",
    "    data, label = [], []\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for img, age in tqdm(executor.map(load_and_resize, df.index), total=len(df)):\n",
    "            if img is not None:\n",
    "                data.append(img)\n",
    "                label.append(age)\n",
    "    return np.array(data), np.array(label)\n",
    "\n",
    "train_data, train_label = load_images_and_labels(\"/work1043/yuhung0716/Final_model/dataset_confounder_train.csv\")\n",
    "test_data, test_label = load_images_and_labels(\"/work1043/yuhung0716/Final_model/dataset_confounder_test.csv\")\n",
    "val_data, val_label = load_images_and_labels(\"/work1043/yuhung0716/Final_model/dataset_confounder_val.csv\")\n",
    "\n",
    "save_dir = \"/home/hank52052/work/code/cfp/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(save_dir, \"ori_train_data.npy\"), train_data)\n",
    "np.save(os.path.join(save_dir, \"ori_train_label.npy\"), train_label)\n",
    "np.save(os.path.join(save_dir, \"ori_test_data.npy\"), test_data)\n",
    "np.save(os.path.join(save_dir, \"ori_test_label.npy\"), test_label)\n",
    "np.save(os.path.join(save_dir, \"ori_val_data.npy\"), val_data)\n",
    "np.save(os.path.join(save_dir, \"ori_val_label.npy\"), val_label)\n",
    "\n",
    "print(\"train_data.shape:\", train_data.shape)\n",
    "print(\"train_label.shape:\", train_label.shape)\n",
    "print(\"test_data.shape:\", test_data.shape)\n",
    "print(\"test_label.shape:\", test_label.shape)\n",
    "print(\"val_data.shape:\", val_data.shape)\n",
    "print(\"val_label.shape:\", val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49bfaf-bb41-41f8-a1e6-6867aaea8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pydicom\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_and_process_images(csv_path, image_dir, image_col, label_col, save_data_path, save_label_path):\n",
    "    df = pd.read_csv(csv_path).dropna(subset=[image_col, label_col])\n",
    "    data, labels = [], []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(image_dir, df.loc[i, image_col]))\n",
    "            img = cv2.resize(img, (299, 299))\n",
    "            img = img[:, :, ::-1]\n",
    "            data.append(img)\n",
    "            labels.append(df.loc[i, label_col])\n",
    "        except:\n",
    "            continue\n",
    "    data, labels = np.array(data), np.array(labels)\n",
    "    np.save(save_data_path, data)\n",
    "    np.save(save_label_path, labels)\n",
    "\n",
    "load_and_process_images(\n",
    "    \"../../Dataset/odir/full_df.csv\",\n",
    "    \"../../Dataset/odir/preprocessed_images/\",\n",
    "    \"filename\",\n",
    "    \"Patient Age\",\n",
    "    \"./original_data/odir_data.npy\",\n",
    "    \"./original_data/odir_label.npy\"\n",
    ")\n",
    "\n",
    "load_and_process_images(\n",
    "    \"../../Dataset/SMG/metadata_standardized.csv\",\n",
    "    \"../../Dataset/SMG/full-fundus/\",\n",
    "    \"fundus\",\n",
    "    \"age\",\n",
    "    \"./original_data/SMG_data.npy\",\n",
    "    \"./original_data/SMG_label.npy\"\n",
    ")\n",
    "\n",
    "predict_data = pd.read_excel(\"./evaluation_dataset/AGE_AI_0512_v2.xlsx\")\n",
    "original_data = pd.read_excel(\"./evaluation_dataset/LAB_0512_V2.xlsx\")\n",
    "predict_data = predict_data.loc[:, [\"CHARGE_NO\", \"ANAMNESIS_NO\", \"Predicted biological age\", \"SEX\"]]\n",
    "original_data = original_data.loc[:, [\"CHARGE_NO\", \"ANAMNESIS_NO\", \"Age\"]]\n",
    "new_data = pd.merge(original_data, predict_data, on=[\"CHARGE_NO\", \"ANAMNESIS_NO\"], how=\"outer\").dropna()\n",
    "\n",
    "dicom_dir = \"./evaluation_dataset/DE-OPDICOM/\"\n",
    "all_files = [\n",
    "    (filename.split(\"@\")[0], os.path.join(dicom_dir, filename))\n",
    "    for filename in os.listdir(dicom_dir) if filename.endswith(\".dcm\")\n",
    "]\n",
    "\n",
    "patients_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "def process_file(patient_file_tuple):\n",
    "    patient_id, filepath = patient_file_tuple\n",
    "    try:\n",
    "        dcm = pydicom.dcmread(filepath, stop_before_pixels=False)\n",
    "        study_date = dcm.get((0x0008, 0x0020), None)\n",
    "        laterality = dcm.get((0x0020, 0x0060), None)\n",
    "        if study_date is None: return None\n",
    "        img = dcm.pixel_array\n",
    "        if img.shape != (2320, 3472, 3): return None\n",
    "        img = img[:, 577:2897, ::-1]\n",
    "        img = cv2.resize(img, (299, 299))\n",
    "        img = img[:, :, ::-1]\n",
    "        return (patient_id, study_date.value, filepath, laterality.value, img)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "    futures = [executor.submit(process_file, pf) for pf in all_files]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"ËôïÁêÜDICOMÊ™îÊ°à\"):\n",
    "        res = future.result()\n",
    "        if res:\n",
    "            patient_id, study_date_val, filepath, laterality_val, img = res\n",
    "            patients_data[patient_id][study_date_val].append((filepath, laterality_val, img))\n",
    "\n",
    "result = {}\n",
    "for patient_id, date_dict in patients_data.items():\n",
    "    latest_date = max(date_dict.keys())\n",
    "    imgs_list = date_dict[latest_date]\n",
    "    left_eye_imgs = [img for _, lat, img in imgs_list if lat == \"L\"]\n",
    "    right_eye_imgs = [img for _, lat, img in imgs_list if lat == \"R\"]\n",
    "    result[patient_id] = {\n",
    "        \"latest_date\": latest_date,\n",
    "        \"left_eye_imgs\": left_eye_imgs,\n",
    "        \"right_eye_imgs\": right_eye_imgs\n",
    "    }\n",
    "\n",
    "right_eye_imgs, left_eye_imgs, bio_ages, ages, sex_all = [], [], [], [], []\n",
    "for _, row in new_data.iterrows():\n",
    "    pid = row['CHARGE_NO']\n",
    "    if pid in result:\n",
    "        right = result[pid].get('right_eye_imgs', [])\n",
    "        left = result[pid].get('left_eye_imgs', [])\n",
    "        if len(right) == 0 or len(left) == 0:\n",
    "            continue\n",
    "        right_eye_imgs.append(right[0].astype(np.uint8))\n",
    "        left_eye_imgs.append(left[0].astype(np.uint8))\n",
    "        bio_ages.append(float(row['Predicted biological age']))\n",
    "        ages.append(float(row['Age']))\n",
    "        sex_all.append(row['SEX'])\n",
    "\n",
    "right_eye_imgs = np.stack(right_eye_imgs)\n",
    "left_eye_imgs = np.stack(left_eye_imgs)\n",
    "bio_ages = np.array(bio_ages, dtype=np.float32)\n",
    "ages = np.array(ages, dtype=np.float32)\n",
    "sex_all = np.array(sex_all)\n",
    "\n",
    "print(\"Âè≥ÁúºÂΩ±ÂÉè shape:\", right_eye_imgs.shape)\n",
    "print(\"Â∑¶ÁúºÂΩ±ÂÉè shape:\", left_eye_imgs.shape)\n",
    "print(\"ÁîüÁâ©Âπ¥ÈΩ° shape:\", bio_ages.shape)\n",
    "print(\"Âπ¥ÈΩ° shape:\", ages.shape)\n",
    "print(\"ÊÄßÂà• shape:\", sex_all.shape)\n",
    "\n",
    "np.save(\"./original_data/bioage_data.npy\", right_eye_imgs)\n",
    "np.save(\"./original_data/bioage_label.npy\", bio_ages)\n",
    "np.save(\"./original_data/bioage_label_chr.npy\", ages)\n",
    "np.save(\"./original_data/bioage_sex.npy\", sex_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8352b-f3b9-43cc-98fd-6b8aee149331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import product\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = \"/home/hank52052/code/cfp/original_data\"\n",
    "\n",
    "def image_sharpness_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "\n",
    "def brightness_penalty(img, threshold=190):\n",
    "    brightness = img.mean()\n",
    "    penalty = max(0, brightness - threshold) ** 2\n",
    "    return penalty\n",
    "\n",
    "def apply_blur_enhance_auto(img):\n",
    "    best_score = -np.inf\n",
    "    best_enhanced = None\n",
    "\n",
    "    ksize_list = [\n",
    "        (3, 3), (5, 5), (7, 7),\n",
    "        (9, 9), (11, 11), (13, 13),\n",
    "        (15, 15), (17, 17), (19, 19)\n",
    "    ]\n",
    "    alpha_list = [1.5, 2.0, 2.5]\n",
    "    beta_list = [-0.8, -1.0, -1.2]\n",
    "    gamma_list = [0, 10, 15]\n",
    "\n",
    "    for ksize, alpha, beta, gamma in product(ksize_list, alpha_list, beta_list, gamma_list):\n",
    "        blurred = cv2.blur(img, ksize)\n",
    "        enhanced = cv2.addWeighted(img, alpha, blurred, beta, gamma)\n",
    "        enhanced = np.clip(enhanced, 0, 255).astype(np.uint8)\n",
    "        sharpness = image_sharpness_score(enhanced)\n",
    "        penalty = brightness_penalty(enhanced, threshold=190)\n",
    "        score = sharpness - 0.05 * penalty\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_enhanced = enhanced\n",
    "\n",
    "    return best_enhanced\n",
    "\n",
    "def process_single_image(img):\n",
    "    return apply_blur_enhance_auto(img)\n",
    "\n",
    "def process_npy_file(filepath):\n",
    "    output_path = filepath.replace(\"_data.npy\", \"_data_process.npy\")\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"[‚è©] Skipping (already processed): {os.path.basename(output_path)}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n[üîç] Processing: {os.path.basename(filepath)}\")\n",
    "    data = np.load(filepath)\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap(process_single_image, data), total=len(data), desc=f\"Enhancing {os.path.basename(filepath)}\"))\n",
    "    result_array = np.array(results, dtype=np.uint8)\n",
    "    np.save(output_path, result_array)\n",
    "    print(f\"[‚úÖ] Saved: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_files = os.listdir(input_dir)\n",
    "    target_files = [os.path.join(input_dir, f) for f in all_files if f.endswith(\"_data.npy\")]\n",
    "\n",
    "    for file_path in target_files:\n",
    "        process_npy_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd48aff-5474-4323-81a3-77f9865095be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 6))\n",
    "ax = plt.subplot(141)\n",
    "ax.axis(\"off\")\n",
    "plt.imshow(SMG_data[8])\n",
    "\n",
    "ax = plt.subplot(142)\n",
    "ax.axis(\"off\")\n",
    "blurred = cv2.bilateralFilter(SMG_data[8][:, :, ::-1], d=5, sigmaColor=25, sigmaSpace=25)\n",
    "plt.imshow(blurred[:, :, ::-1])\n",
    "\n",
    "ax = plt.subplot(143)\n",
    "ax.axis(\"off\")\n",
    "blurred = cv2.bilateralFilter(SMG_data[8][:, :, ::-1], d=9, sigmaColor=75, sigmaSpace=75)\n",
    "plt.imshow(blurred[:, :, ::-1])\n",
    "\n",
    "ax = plt.subplot(144)\n",
    "ax.axis(\"off\")\n",
    "blurred = cv2.bilateralFilter(SMG_data[8][:, :, ::-1], d=15, sigmaColor=150, sigmaSpace=150)\n",
    "plt.imshow(blurred[:, :, ::-1])\n",
    "\n",
    "plt.savefig(\"blue_show.png\", dpi=400, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
